{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMr/0+B1Hw7M4bOdJcY9a55",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amanglarus/image_classification_using-tensorflow/blob/main/classification_using_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlyECQNKPppm",
        "outputId": "cd571994-9ad0-474c-b9c8-c0c38a7b5c17"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/tshirt_laptop_data.zip /content/"
      ],
      "metadata": {
        "id": "8TqXEThNQCtk"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip tshirt_laptop_data.zip"
      ],
      "metadata": {
        "id": "FOfkvKKKQCwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!rm -r tshirt_laptop_data"
      ],
      "metadata": {
        "id": "6gyRaAe-OwTT"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert all images to gray scale images"
      ],
      "metadata": {
        "id": "z34bvY1LT5Ff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rgb_to_gray(rgb_img): # provide image in rgb order not in bgr or any other order\n",
        "\n",
        "  gamma = 1.04\n",
        "  r_const, g_const, b_const = 0.2126, 0.7152, 0.0722\n",
        "\n",
        "  r, g, b = rgb_img[:,:,0], rgb_img[:,:,1], rgb_img[:,:,2]\n",
        "\n",
        "  gray_img = r_const*r**gamma + g_const*g**gamma + b_const*b**gamma\n",
        "\n",
        "  return gray_img"
      ],
      "metadata": {
        "id": "luo_3LfmT_D-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grey_img = True\n",
        "\n",
        "import glob\n",
        "import cv2\n",
        "dir_name = \"/content/tshirt_laptop_data\"+\"/*\"\n",
        "if grey_img:\n",
        "    for folder_name in glob.glob(dir_name):\n",
        "      for data_type_path in glob.glob(folder_name+\"/*\"):\n",
        "          for img_path in glob.glob(data_type_path+\"/*\"):\n",
        "              \n",
        "              img = cv2.imread(img_path) #BGR color map\n",
        "              rgb_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) # BGR to RGB\n",
        "              gray = rgb_to_gray(rgb_img)\n",
        "              cv2.imwrite(img_path, gray)\n"
      ],
      "metadata": {
        "id": "tespa1ZdOwV3"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NtmcEygSOjm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install specific tensorflow version "
      ],
      "metadata": {
        "id": "xPAXleRl6CPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gpu==2.4.0"
      ],
      "metadata": {
        "id": "VCOBlSpL6Bvz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "394788d4-95c8-4261-9699-ef7564166a32"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-gpu==2.4.0\n",
            "  Downloading tensorflow_gpu-2.4.0-cp38-cp38-manylinux2010_x86_64.whl (394.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.8/394.8 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy~=1.19.2\n",
            "  Downloading numpy-1.19.5-cp38-cp38-manylinux2010_x86_64.whl (14.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu==2.4.0) (2.11.2)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu==2.4.0) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu==2.4.0) (3.3.0)\n",
            "Collecting h5py~=2.10.0\n",
            "  Downloading h5py-2.10.0-cp38-cp38-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu==2.4.0) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu==2.4.0) (3.19.6)\n",
            "Collecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting termcolor~=1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorflow-estimator<2.5.0,>=2.4.0rc0\n",
            "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.0/462.0 KB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting grpcio~=1.32.0\n",
            "  Downloading grpcio-1.32.0-cp38-cp38-manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu==2.4.0) (0.38.4)\n",
            "Collecting keras-preprocessing~=1.1.2\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu==2.4.0) (1.15.0)\n",
            "Collecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.0) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.0) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.0) (2.16.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.0) (2.25.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.0) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.0) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.0) (3.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.0) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.0) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu==2.4.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu==2.4.0) (6.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.0) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.0) (2022.12.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu==2.4.0) (3.13.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu==2.4.0) (3.2.2)\n",
            "Building wheels for collected packages: termcolor, wrapt\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4849 sha256=6d632e84e64b06473cbec679a8f3b72a5cbaeb45317b00203e407fc9d3d2643f\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp38-cp38-linux_x86_64.whl size=78579 sha256=5518f6a7f0e2c5e10d5e2865556f7a007aa59002800344809830807be2281641\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/fd/9e/b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\n",
            "Successfully built termcolor wrapt\n",
            "Installing collected packages: wrapt, typing-extensions, termcolor, tensorflow-estimator, flatbuffers, numpy, grpcio, gast, absl-py, keras-preprocessing, h5py, tensorflow-gpu\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 2.2.0\n",
            "    Uninstalling termcolor-2.2.0:\n",
            "      Successfully uninstalled termcolor-2.2.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.11.0\n",
            "    Uninstalling tensorflow-estimator-2.11.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.11.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 23.1.21\n",
            "    Uninstalling flatbuffers-23.1.21:\n",
            "      Successfully uninstalled flatbuffers-23.1.21\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.51.1\n",
            "    Uninstalling grpcio-1.51.1:\n",
            "      Successfully uninstalled grpcio-1.51.1\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.4.0\n",
            "    Uninstalling absl-py-1.4.0:\n",
            "      Successfully uninstalled absl-py-1.4.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray 2022.12.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "xarray-einstats 0.5.1 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "tensorflow 2.11.0 requires absl-py>=1.0.0, but you have absl-py 0.15.0 which is incompatible.\n",
            "tensorflow 2.11.0 requires flatbuffers>=2.0, but you have flatbuffers 1.12 which is incompatible.\n",
            "tensorflow 2.11.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "tensorflow 2.11.0 requires tensorflow-estimator<2.12,>=2.11.0, but you have tensorflow-estimator 2.4.0 which is incompatible.\n",
            "pydantic 1.10.5 requires typing-extensions>=4.2.0, but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "jaxlib 0.3.25+cuda11.cudnn805 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "jax 0.3.25 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "grpcio-status 1.48.2 requires grpcio>=1.48.2, but you have grpcio 1.32.0 which is incompatible.\n",
            "google-cloud-bigquery 3.4.2 requires grpcio<2.0dev,>=1.47.0, but you have grpcio 1.32.0 which is incompatible.\n",
            "cmdstanpy 1.1.0 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed absl-py-0.15.0 flatbuffers-1.12 gast-0.3.3 grpcio-1.32.0 h5py-2.10.0 keras-preprocessing-1.1.2 numpy-1.19.5 tensorflow-estimator-2.4.0 tensorflow-gpu-2.4.0 termcolor-1.1.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5_FjV1k5_wg",
        "outputId": "42de9adc-2205-43f9-d5da-6bae7793e94e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q3r7VVtk6AQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oBxCFEGCis-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data in pipe line to tarin the model"
      ],
      "metadata": {
        "id": "JmT3vZhI31fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D,Dense,Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, ZeroPadding2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.models import Model, Sequential"
      ],
      "metadata": {
        "id": "7jes4eSpQC1S"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zOkBf541aeQm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 2\n",
        "BATCH_SIZE=32\n",
        "IMAGE_SIZE = 96\n",
        "NUM_CHANNEL = 1\n",
        "\n",
        "IMAGE_SHAPE = (IMAGE_SIZE, IMAGE_SIZE)\n",
        "MODEL_IMAGE_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNEL)"
      ],
      "metadata": {
        "id": "TfsrnPgMaeS1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_data_dir='/content/tshirt_laptop_data/train'\n",
        "val_data_dir='/content/tshirt_laptop_data/test'\n",
        "\n",
        "# from tensorflow.keras.layers.preprocessing.image_preprocessing import HORIZONTAL\n",
        "\n",
        "train_datagen=ImageDataGenerator(rescale=1./255,\n",
        "                                 rotation_range=10,\n",
        "                                 width_shift_range=0.1,\n",
        "                                 height_shift_range=0.1,\n",
        "                                 horizontal_flip=True,\n",
        "                                 fill_mode='nearest')\n",
        "\n",
        "val_datagen=ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_generator=train_datagen.flow_from_directory(train_data_dir,\n",
        "                                                  target_size=IMAGE_SHAPE,\n",
        "                                                  batch_size=BATCH_SIZE,\n",
        "                                                  color_mode=\"grayscale\",\n",
        "                                                  class_mode='sparse')\n",
        "\n",
        "val_generator=val_datagen.flow_from_directory(val_data_dir,\n",
        "                                              target_size=IMAGE_SHAPE,\n",
        "                                              batch_size=BATCH_SIZE,\n",
        "                                              color_mode=\"grayscale\",\n",
        "                                              class_mode='sparse')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCRDX1OyPk91",
        "outputId": "e10f7fc4-8bc1-4400-88a1-7c9ccfe3fa4e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2385 images belonging to 2 classes.\n",
            "Found 200 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Model"
      ],
      "metadata": {
        "id": "zL479Jog3oP_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zcwmu73TQjmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_toJDoxJSrVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mobilenet V3 from scratch\n"
      ],
      "metadata": {
        "id": "AcZN5i1uQjtn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code taken from here : https://github.com/sirius-ai/MobileNetV3-TF/blob/master/MobileNetV3.pyhttps://github.com/sirius-ai/MobileNetV3-TF/blob/master/MobileNetV3.py\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "MobileNetV3_Small_Spec = [\n",
        "    # Op            k    exp    out    SE     NL        s\n",
        "    [ \"ConvBnAct\",  3,   False, 16,    False, \"hswish\", 2 ],\n",
        "    [ \"bneck\",      3,   16,    16,    True,  \"relu\",   2 ],\n",
        "    [ \"bneck\",      3,   72,    24,    False, \"relu\",   2 ],\n",
        "    [ \"bneck\",      3,   88,    24,    False, \"relu\",   1 ],\n",
        "    [ \"bneck\",      5,   96,    40,    True,  \"hswish\", 2 ],\n",
        "    [ \"bneck\",      5,   240,   40,    True,  \"hswish\", 1 ],\n",
        "    [ \"bneck\",      5,   240,   40,    True,  \"hswish\", 1 ],\n",
        "    [ \"bneck\",      5,   120,   48,    True,  \"hswish\", 1 ],\n",
        "    [ \"bneck\",      5,   144,   48,    True,  \"hswish\", 1 ],\n",
        "    [ \"bneck\",      5,   288,   96,    True,  \"hswish\", 2 ],\n",
        "    [ \"bneck\",      5,   576,   96,    True,  \"hswish\", 1 ],\n",
        "    [ \"bneck\",      5,   576,   96,    True,  \"hswish\", 1 ],\n",
        "    [ \"ConvBnAct\",  1,   False, 576,   True,  \"hswish\", 1 ],\n",
        "    [ \"pool\",       7,   False, False, False, \"None\",   1 ],\n",
        "    [ \"ConvNBnAct\", 1,   False, 1280,  False, \"hswish\", 1 ],\n",
        "    [ \"ConvNBnAct\", 1,   False, 1000,  False, \"None\",   1 ],\n",
        "]\n",
        "\n",
        "\n",
        "MobileNetV3_Large_Spec = [\n",
        "    # Op            k    exp    out    SE     NL        s\n",
        "    [ \"ConvBnAct\",  3,   False, 16,    False, \"hswish\", 2 ],\n",
        "    [ \"bneck\",      3,   16,    16,    False, \"relu\",   1 ],\n",
        "    [ \"bneck\",      3,   64,    24,    False, \"relu\",   2 ],\n",
        "    [ \"bneck\",      3,   72,    24,    False, \"relu\",   1 ],\n",
        "    [ \"bneck\",      5,   72,    40,    True,  \"relu\",   2 ],\n",
        "    [ \"bneck\",      5,   120,   40,    True,  \"relu\",   1 ],\n",
        "    [ \"bneck\",      5,   120,   40,    True,  \"relu\",   1 ],\n",
        "    [ \"bneck\",      3,   240,   80,    False, \"hswish\", 2 ],\n",
        "    [ \"bneck\",      3,   200,   80,    False, \"hswish\", 1 ],\n",
        "    [ \"bneck\",      3,   184,   80,    False, \"hswish\", 1 ],\n",
        "    [ \"bneck\",      3,   184,   80,    False, \"hswish\", 1 ],\n",
        "    [ \"bneck\",      3,   480,   112,   True,  \"hswish\", 1 ],\n",
        "    [ \"bneck\",      3,   672,   112,   True,  \"hswish\", 1 ],\n",
        "    [ \"bneck\",      5,   672,   160,   True,  \"hswish\", 2 ],\n",
        "    [ \"bneck\",      5,   960,   160,   True,  \"hswish\", 1 ],\n",
        "    [ \"bneck\",      5,   960,   160,   True,  \"hswish\", 1 ],\n",
        "    [ \"ConvBnAct\",  1,   False, 960,   False, \"hswish\", 1 ],\n",
        "    [ \"pool\",       7,   False, False, False, \"None\",   1 ],\n",
        "    [ \"ConvNBnAct\", 1,   False, 1280,  False, \"hswish\", 1 ],\n",
        "    [ \"ConvNBnAct\", 1,   False, 1000,  False, \"None\",   1 ],\n",
        "]\n",
        "\n",
        "def _make_divisible(v, divisor, min_value=None):\n",
        "    if min_value is None:\n",
        "        min_value = divisor\n",
        "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
        "\n",
        "    # Make sure that round down does not go down by more than 10%.\n",
        "    if new_v < 0.9 * v:\n",
        "        new_v += divisor\n",
        "\n",
        "    return new_v\n",
        "\n",
        "class Identity(tf.keras.layers.Layer):\n",
        "    def __init__(self, name=\"Identity\", **kwargs):\n",
        "        super(Identity, self).__init__(name=name, **kwargs)\n",
        "\n",
        "    def call(self, input):\n",
        "        return input\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super(Identity, self).get_config()\n",
        "        return dict(list(base_config.items()))\n",
        "\n",
        "class HardSigmoid(tf.keras.layers.Layer):\n",
        "    def __init__(self, name=\"HardSigmoid\", **kwargs):\n",
        "        super(HardSigmoid, self).__init__(name=name, **kwargs)\n",
        "        self.relu6 = tf.keras.layers.ReLU(max_value=6, name=\"ReLU6\", **kwargs)\n",
        "\n",
        "    def call(self, input):\n",
        "        return self.relu6(input + 3.0) / 6.0\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super(HardSigmoid, self).get_config()\n",
        "        return dict(list(base_config.items()))\n",
        "\n",
        "class HardSwish(tf.keras.layers.Layer):\n",
        "    def __init__(self, name=\"HardSwish\", **kwargs):\n",
        "        super(HardSwish, self).__init__(name=name, **kwargs)\n",
        "        self.relu6 = tf.keras.layers.ReLU(max_value=6, name=\"ReLU6\", **kwargs)\n",
        "\n",
        "    def call(self, input):\n",
        "        return input * self.relu6(input + 3.0) / 6.0\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super(HardSwish, self).get_config()\n",
        "        return dict(list(base_config.items()))\n",
        "\n",
        "_available_activation = {\n",
        "            \"relu\": tf.keras.layers.ReLU(name=\"ReLU\"),\n",
        "            \"relu6\": tf.keras.layers.ReLU(max_value=6, name=\"ReLU6\"),\n",
        "            \"hswish\": HardSwish(),\n",
        "            \"hsigmoid\": HardSigmoid(),\n",
        "            \"softmax\": tf.keras.layers.Softmax(name=\"Softmax\"),\n",
        "            \"None\": Identity(),\n",
        "        }\n",
        "\n",
        "class SENet(tf.keras.layers.Layer):\n",
        "    def __init__(self, reduction=4, l2=2e-4, name=\"SENet\", **kwargs):\n",
        "        super(SENet, self).__init__(name=name, **kwargs)\n",
        "        self.reduction = reduction\n",
        "        self.l2 = l2\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        _, h, w, c = input_shape\n",
        "        self.gap = tf.keras.layers.GlobalAveragePooling2D(name=f'AvgPool{h}x{w}')\n",
        "        self.fc1 = tf.keras.layers.Dense(units=c//self.reduction, activation=\"relu\", use_bias=False,\n",
        "                                         kernel_regularizer=tf.keras.regularizers.l2(self.l2), name=\"Squeeze\")\n",
        "        self.fc2 = tf.keras.layers.Dense(units=c, activation=HardSigmoid(), use_bias=False,\n",
        "                                         kernel_regularizer=tf.keras.regularizers.l2(self.l2), name=\"Excite\")\n",
        "        self.reshape = tf.keras.layers.Reshape((1, 1, c), name=f'Reshape_None_1_1_{c}')\n",
        "\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, input):\n",
        "        output = self.gap(input)\n",
        "        output = self.fc1(output)\n",
        "        output = self.fc2(output)\n",
        "        output = self.reshape(output)\n",
        "        return input * output\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\"reduction\":self.reduction, \"l2\":self.l2}\n",
        "        base_config = super(SENet, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "class ConvBnAct(tf.keras.layers.Layer):\n",
        "    def __init__(self, k, exp, out, SE, NL, s, l2, name=\"ConvBnAct\", **kwargs):\n",
        "        super(ConvBnAct, self).__init__(name=name, **kwargs)\n",
        "        self.k = k\n",
        "        self.exp = exp\n",
        "        self.out = out\n",
        "        self.se = SE\n",
        "        self.nl = NL\n",
        "        self.s = s\n",
        "        self.l2 = l2\n",
        "        self.conv2d = tf.keras.layers.Conv2D(filters=out, kernel_size=k, strides=s, activation=None, padding=\"same\",\n",
        "                                             kernel_regularizer=tf.keras.regularizers.l2(l2), name=\"conv2d\", **kwargs)\n",
        "        self.bn = tf.keras.layers.BatchNormalization(momentum=0.99, name=\"BatchNormalization\", **kwargs)\n",
        "        self.act = _available_activation[NL]\n",
        "\n",
        "    def call(self, input):\n",
        "        output = self.conv2d(input)\n",
        "        output = self.bn(output)\n",
        "        output = self.act(output)\n",
        "        return output\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\"k\":self.k, \"exp\":self.exp, \"out\":self.out, \"SE\":self.se, \"NL\":self.nl, \"s\":self.s, \"l2\":self.l2}\n",
        "        base_config = super(ConvBnAct, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "class ConvNBnAct(tf.keras.layers.Layer):\n",
        "    def __init__(self, k, exp, out, SE, NL, s, l2, name=\"ConvNBnAct\", **kwargs):\n",
        "        super(ConvNBnAct, self).__init__(name=name, **kwargs)\n",
        "        self.k = k\n",
        "        self.exp = exp\n",
        "        self.out = out\n",
        "        self.se = SE\n",
        "        self.nl = NL\n",
        "        self.s = s\n",
        "        self.l2 = l2\n",
        "        self.act = _available_activation[NL]\n",
        "        self.fn = tf.keras.layers.Conv2D(filters=out, kernel_size=k, strides=s, activation=self.act, padding=\"same\",\n",
        "                                         kernel_regularizer=tf.keras.regularizers.l2(l2),name=\"conv2d\", **kwargs)\n",
        "\n",
        "    def call(self, input):\n",
        "        output = self.fn(input)\n",
        "        return output\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\"k\":self.k, \"exp\":self.exp, \"out\":self.out, \"SE\":self.se, \"NL\":self.nl, \"s\":self.s, \"l2\":self.l2}\n",
        "        base_config = super(ConvNBnAct, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "class Pool(tf.keras.layers.Layer):\n",
        "    def __init__(self, k, exp, out, SE, NL, s, l2, name=\"Pool\", **kwargs):\n",
        "        super(Pool, self).__init__(name=name, **kwargs)\n",
        "        self.k = k\n",
        "        self.exp = exp\n",
        "        self.out = out\n",
        "        self.se = SE\n",
        "        self.nl = NL\n",
        "        self.s = s\n",
        "        self.l2 = l2\n",
        "        self.gap = tf.keras.layers.AveragePooling2D(pool_size=(k, k), strides=1, name=f'AvgPool{k}x{k}', **kwargs)\n",
        "\n",
        "    def call(self, input):\n",
        "        output = self.gap(input)\n",
        "        return output\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\"k\":self.k, \"exp\":self.exp, \"out\":self.out, \"SE\":self.se, \"NL\":self.nl, \"s\":self.s, \"l2\":self.l2}\n",
        "        base_config = super(Pool, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "class BottleNeck(tf.keras.layers.Layer):\n",
        "    def __init__(self, k, exp, out, SE, NL, s, l2, name=\"BottleNeck\", **kwargs):\n",
        "        super(BottleNeck, self).__init__(name=name, **kwargs)\n",
        "        self.k = k\n",
        "        self.exp = exp\n",
        "        self.out = out\n",
        "        self.se = SE\n",
        "        self.nl = NL\n",
        "        self.s = s\n",
        "        self.l2 = l2\n",
        "        self.expand = ConvBnAct(k=1, exp=exp, out=exp, SE=SE, NL=NL, s=1, l2=l2, name=\"BottleNeckExpand\", **kwargs)\n",
        "        self.depthwise = tf.keras.layers.DepthwiseConv2D(\n",
        "            kernel_size=k,\n",
        "            strides=s,\n",
        "            padding=\"same\",\n",
        "            use_bias=False,\n",
        "            depthwise_regularizer=tf.keras.regularizers.l2(l2),\n",
        "            name=f'Depthwise{k}x{k}',\n",
        "            ** kwargs,\n",
        "        )\n",
        "        self.pointwise = tf.keras.layers.Conv2D(\n",
        "            filters=out,\n",
        "            kernel_size=1,\n",
        "            strides=1,\n",
        "            use_bias=False,\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(l2),\n",
        "            name=f'Pointwise1x1',\n",
        "            ** kwargs,\n",
        "        )\n",
        "        self.bn_1 = tf.keras.layers.BatchNormalization(momentum=0.99, name=\"BatchNormalization_1\", **kwargs)\n",
        "        self.bn_2 = tf.keras.layers.BatchNormalization(momentum=0.99, name=\"BatchNormalization_2\", **kwargs)\n",
        "\n",
        "        if self.se:\n",
        "            self.SeNet = SENet(name=\"SEBottleneck\", l2=l2, **kwargs)\n",
        "\n",
        "        self.act = _available_activation[NL]\n",
        "\n",
        "    def call(self, input):\n",
        "        output = self.expand(input)\n",
        "        output = self.depthwise(output)\n",
        "        output = self.bn_1(output)\n",
        "        if self.se:\n",
        "            output = self.SeNet(output)\n",
        "        output = self.act(output)\n",
        "        output = self.pointwise(output)\n",
        "        output = self.bn_2(output)\n",
        "\n",
        "        if self.s == 1 and self.exp == self.out:\n",
        "            return input + output\n",
        "        else:\n",
        "            return output\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\"k\":self.k, \"exp\":self.exp, \"out\":self.out, \"SE\":self.se, \"NL\":self.nl, \"s\":self.s, \"l2\":self.l2}\n",
        "        base_config = super(BottleNeck, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "_available_mobilenetv3_spec = {\n",
        "            \"small\": MobileNetV3_Small_Spec,\n",
        "            \"large\": MobileNetV3_Large_Spec,\n",
        "        }\n",
        "\n",
        "_available_operation = {\n",
        "            \"ConvBnAct\":  ConvBnAct,\n",
        "            \"bneck\":      BottleNeck,\n",
        "            \"pool\":       Pool,\n",
        "            \"ConvNBnAct\": ConvNBnAct,\n",
        "        }\n",
        "\n",
        "class CusReshape(tf.keras.layers.Layer):\n",
        "    def __init__(self, out, name=\"Reshape\", **kwargs):\n",
        "        super(CusReshape, self).__init__(name=name, **kwargs)\n",
        "        self.out = out\n",
        "        self.reshape = tf.keras.layers.Reshape((out,), name=f'Reshape_None_{out}', **kwargs)\n",
        "\n",
        "    def call(self, input):\n",
        "        output = self.reshape(input)\n",
        "        return output\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\"out\":self.out}\n",
        "        base_config = super(CusReshape, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "class CusDropout(tf.keras.layers.Layer):\n",
        "    def __init__(self, dropout_rate, name=\"Dropout\", **kwargs):\n",
        "        super(CusDropout, self).__init__(name=name, **kwargs)\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.dropout = tf.keras.layers.Dropout(rate=dropout_rate, name=f'Dropout', **kwargs)\n",
        "\n",
        "    def call(self, input):\n",
        "        output = self.dropout(input)\n",
        "        return output\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\"dropout_rate\":self.dropout_rate}\n",
        "        base_config = super(CusDropout, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "def MobileNetV3(type=\"large\", input_shape=(224, 224, 3), classes_number=2, width_multiplier=1.0,\n",
        "                divisible_by=8, l2_reg=2e-5, dropout_rate=0.2, name=\"MobileNetV3\"):\n",
        "    spec = _available_mobilenetv3_spec[type]\n",
        "    spec[-1][3] = classes_number  # bottlenet layer size or class numbers\n",
        "    name = name + \"_\" + type\n",
        "\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape, name=\"inputs\")\n",
        "\n",
        "    for i, params in enumerate(spec):\n",
        "        Op, k, exp, out, SE, NL, s = params\n",
        "        inference_op = _available_operation[Op]\n",
        "\n",
        "        if isinstance(exp, int):\n",
        "            exp_ch = _make_divisible(exp * width_multiplier, divisible_by)\n",
        "        else:\n",
        "            exp_ch = None\n",
        "        if isinstance(out, int):\n",
        "            out_ch = _make_divisible(out * width_multiplier, divisible_by)\n",
        "        else:\n",
        "            out_ch = None\n",
        "        if i == len(spec) - 1:  # fix output classes error.\n",
        "            out_ch = classes_number\n",
        "\n",
        "        op_name = f'{Op}_{i}'\n",
        "        if i == 0:\n",
        "            output = inference_op(k, exp_ch, out_ch, SE, NL, s, l2_reg, op_name)(inputs)\n",
        "        else:\n",
        "            output = inference_op(k, exp_ch, out_ch, SE, NL, s, l2_reg, op_name)(output)\n",
        "\n",
        "        if (type == \"small\" and i == 14) or (type == \"large\" and i == 18):\n",
        "            output = CusDropout(dropout_rate=dropout_rate)(output)\n",
        "\n",
        "    outputs = CusReshape(out=classes_number)(output)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=name)\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "custom_objects = {\n",
        "    \"ConvBnAct\" :  ConvBnAct,\n",
        "    \"BottleNeck\":  BottleNeck,\n",
        "    \"Pool\"      :  Pool,\n",
        "    \"ConvNBnAct\":  ConvNBnAct,\n",
        "    \"CusReshape\":  CusReshape,\n",
        "    \"CusDropout\":  CusDropout,\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "for gpu in tf.config.experimental.list_physical_devices('GPU'):\n",
        "    tf.compat.v2.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "model = MobileNetV3(type=\"small\")\n",
        "\n",
        "# model = MobileNetV3(type=\"large\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dcS0I4yDANn",
        "outputId": "8ad0efb8-46dc-4b2a-c8e6-e634ececbe26"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"MobileNetV3_small\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inputs (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " ConvBnAct_0 (ConvBnAct)     (None, 112, 112, 16)      512       \n",
            "                                                                 \n",
            " bneck_1 (BottleNeck)        (None, 56, 56, 16)        992       \n",
            "                                                                 \n",
            " bneck_2 (BottleNeck)        (None, 28, 28, 24)        4272      \n",
            "                                                                 \n",
            " bneck_3 (BottleNeck)        (None, 28, 28, 24)        5904      \n",
            "                                                                 \n",
            " bneck_4 (BottleNeck)        (None, 14, 14, 40)        14176     \n",
            "                                                                 \n",
            " bneck_5 (BottleNeck)        (None, 14, 14, 40)        56320     \n",
            "                                                                 \n",
            " bneck_6 (BottleNeck)        (None, 14, 14, 40)        56320     \n",
            "                                                                 \n",
            " bneck_7 (BottleNeck)        (None, 14, 14, 48)        22032     \n",
            "                                                                 \n",
            " bneck_8 (BottleNeck)        (None, 14, 14, 48)        29280     \n",
            "                                                                 \n",
            " bneck_9 (BottleNeck)        (None, 7, 7, 96)          93120     \n",
            "                                                                 \n",
            " bneck_10 (BottleNeck)       (None, 7, 7, 96)          296448    \n",
            "                                                                 \n",
            " bneck_11 (BottleNeck)       (None, 7, 7, 96)          296448    \n",
            "                                                                 \n",
            " ConvBnAct_12 (ConvBnAct)    (None, 7, 7, 576)         58176     \n",
            "                                                                 \n",
            " pool_13 (Pool)              (None, 1, 1, 576)         0         \n",
            "                                                                 \n",
            " ConvNBnAct_14 (ConvNBnAct)  (None, 1, 1, 1280)        738560    \n",
            "                                                                 \n",
            " Dropout (CusDropout)        (None, 1, 1, 1280)        0         \n",
            "                                                                 \n",
            " ConvNBnAct_15 (ConvNBnAct)  (None, 1, 1, 2)           2562      \n",
            "                                                                 \n",
            " Reshape (CusReshape)        (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,675,122\n",
            "Trainable params: 1,662,978\n",
            "Non-trainable params: 12,144\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def conv_block(inputs, filters, kernel_size, strides, use_bias=True):\n",
        "    x = tf.keras.layers.Conv2D(filters, kernel_size, strides=strides, padding='same', use_bias=use_bias)(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    return x\n",
        "\n",
        "def depthwise_conv_block(inputs, strides, use_bias=True):\n",
        "    x = tf.keras.layers.DepthwiseConv2D(kernel_size, strides=strides, padding='same', use_bias=use_bias)(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "\n",
        "def bottleneck(inputs, filters, kernel_size, expansion_factor, strides, use_bias=True):\n",
        "    in_channels = inputs.shape[-1]\n",
        "    x = depthwise_conv_block(inputs, 1, use_bias)\n",
        "    x = depthwise_conv_block(x, 1 use_bias)\n",
        "    x = tf.keras.layers.Conv2D(filters, 1, strides=1, padding='same', use_bias=use_bias)(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    if strides == 1 and in_channels == filters:\n",
        "        x = tf.keras.layers.Add()([x, inputs])\n",
        "    return x\n",
        "\n",
        "def mobilenetv3_small(input_shape, num_classes):\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "\n",
        "\n",
        "    # # x3 = tf.keras.layers.Conv2D(1, 3, strides=1, padding='valid', use_bias=True)(inputs)\n",
        "    # # x3 = tf.keras.layers.BatchNormalization()(x3)\n",
        "    # # x3 = tf.keras.layers.ReLU()(x3)\n",
        "    x1 = tf.keras.layers.AveragePooling2D(pool_size=(5, 5), strides=3)(inputs)\n",
        "    x2 = tf.keras.layers.MaxPooling2D(pool_size=(5, 5), strides=3)(inputs)\n",
        "    x = tf.keras.layers.Concatenate()([x1, x2])\n",
        "\n",
        "    x = conv_block(x, 4, 3, strides=2)\n",
        "    x = bottleneck(x, 6, 3, expansion_factor=1, strides=2)\n",
        "    x = bottleneck(x, 6, 5, expansion_factor=1, strides=1)\n",
        "    x = bottleneck(x, 6, 5, expansion_factor=1, strides=1)\n",
        "    # x = bottleneck(x, 16, 5, expansion_factor=3, strides=2)\n",
        "    # x = bottleneck(x, 16, 5, expansion_factor=3, strides=1)\n",
        "    # x = bottleneck(x, 16, 5, expansion_factor=3, strides=1)\n",
        "    # x = conv_block(x, 8, 1, strides=1)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = tf.keras.layers.Dense(48)(x)\n",
        "    x = tf.keras.layers.ReLU(6.)(x)\n",
        "    x = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "    return tf.keras.Model(inputs, x)\n",
        "\n",
        "# example usage\n",
        "model = mobilenetv3_small(input_shape=MODEL_IMAGE_SHAPE, num_classes=NUM_CLASSES)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "Acg6NyiO_2KC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def conv_block(inputs, filters, kernel_size, strides, use_bias=True):\n",
        "    x = tf.keras.layers.Conv2D(filters, kernel_size, strides=strides, padding='same', use_bias=use_bias)(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    return x\n",
        "\n",
        "def depthwise_conv_block(inputs, strides, use_bias=True):\n",
        "    x = tf.keras.layers.DepthwiseConv2D(kernel_size, strides=strides, padding='same', use_bias=use_bias)(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "\n",
        "def bottleneck(inputs, filters, kernel_size, expansion_factor, strides, use_bias=True):\n",
        "    in_channels = inputs.shape[-1]\n",
        "    x = conv_block(inputs, expansion_factor * in_channels, 1, 1, use_bias)\n",
        "    x = conv_block(x, expansion_factor * in_channels, kernel_size, strides, use_bias)\n",
        "    x = tf.keras.layers.Conv2D(filters, 1, strides=1, padding='same', use_bias=use_bias)(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    if strides == 1 and in_channels == filters:\n",
        "        x = tf.keras.layers.Add()([x, inputs])\n",
        "    return x\n",
        "\n",
        "def mobilenetv3_small(input_shape, num_classes):\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "\n",
        "    x1 = tf.keras.layers.AveragePooling2D(pool_size=(5, 5), strides=3)(inputs)\n",
        "    x2 = tf.keras.layers.MaxPooling2D(pool_size=(5, 5), strides=3)(inputs)\n",
        "    # # x3 = tf.keras.layers.Conv2D(1, 3, strides=1, padding='valid', use_bias=True)(inputs)\n",
        "    # # x3 = tf.keras.layers.BatchNormalization()(x3)\n",
        "    # # x3 = tf.keras.layers.ReLU()(x3)\n",
        "    x = tf.keras.layers.Concatenate()([x1, x2])\n",
        "\n",
        "    x = conv_block(x, 4, 3, strides=2)\n",
        "    x = bottleneck(x, 6, 3, expansion_factor=1, strides=2)\n",
        "    x = bottleneck(x, 6, 5, expansion_factor=1, strides=1)\n",
        "    x = bottleneck(x, 6, 5, expansion_factor=1, strides=1)\n",
        "    # x = bottleneck(x, 16, 5, expansion_factor=3, strides=2)\n",
        "    # x = bottleneck(x, 16, 5, expansion_factor=3, strides=1)\n",
        "    # x = bottleneck(x, 16, 5, expansion_factor=3, strides=1)\n",
        "    # x = conv_block(x, 8, 1, strides=1)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = tf.keras.layers.Dense(48)(x)\n",
        "    x = tf.keras.layers.ReLU(6.)(x)\n",
        "    x = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "    return tf.keras.Model(inputs, x)\n",
        "\n",
        "# example usage\n",
        "model = mobilenetv3_small(input_shape=MODEL_IMAGE_SHAPE, num_classes=NUM_CLASSES)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmgpFEkKTMYF",
        "outputId": "16d2b768-c5cf-4dd0-ffff-6996a5ba50b0"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_18\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_30 (InputLayer)           [(None, 96, 96, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_13 (AveragePo (None, 31, 31, 1)    0           input_30[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling2D) (None, 31, 31, 1)    0           input_30[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 31, 31, 2)    0           average_pooling2d_13[0][0]       \n",
            "                                                                 max_pooling2d_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_260 (Conv2D)             (None, 16, 16, 4)    76          concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_260 (BatchN (None, 16, 16, 4)    16          conv2d_260[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_360 (ReLU)                (None, 16, 16, 4)    0           batch_normalization_260[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_261 (Conv2D)             (None, 16, 16, 4)    20          re_lu_360[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_261 (BatchN (None, 16, 16, 4)    16          conv2d_261[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_361 (ReLU)                (None, 16, 16, 4)    0           batch_normalization_261[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_262 (Conv2D)             (None, 8, 8, 4)      148         re_lu_361[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_262 (BatchN (None, 8, 8, 4)      16          conv2d_262[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_362 (ReLU)                (None, 8, 8, 4)      0           batch_normalization_262[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_263 (Conv2D)             (None, 8, 8, 6)      30          re_lu_362[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_263 (BatchN (None, 8, 8, 6)      24          conv2d_263[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_264 (Conv2D)             (None, 8, 8, 6)      42          batch_normalization_263[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_264 (BatchN (None, 8, 8, 6)      24          conv2d_264[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_363 (ReLU)                (None, 8, 8, 6)      0           batch_normalization_264[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_265 (Conv2D)             (None, 8, 8, 6)      906         re_lu_363[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_265 (BatchN (None, 8, 8, 6)      24          conv2d_265[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_364 (ReLU)                (None, 8, 8, 6)      0           batch_normalization_265[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_266 (Conv2D)             (None, 8, 8, 6)      42          re_lu_364[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_266 (BatchN (None, 8, 8, 6)      24          conv2d_266[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_75 (Add)                    (None, 8, 8, 6)      0           batch_normalization_266[0][0]    \n",
            "                                                                 batch_normalization_263[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_267 (Conv2D)             (None, 8, 8, 6)      42          add_75[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_267 (BatchN (None, 8, 8, 6)      24          conv2d_267[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_365 (ReLU)                (None, 8, 8, 6)      0           batch_normalization_267[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_268 (Conv2D)             (None, 8, 8, 6)      906         re_lu_365[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_268 (BatchN (None, 8, 8, 6)      24          conv2d_268[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_366 (ReLU)                (None, 8, 8, 6)      0           batch_normalization_268[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_269 (Conv2D)             (None, 8, 8, 6)      42          re_lu_366[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_269 (BatchN (None, 8, 8, 6)      24          conv2d_269[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_76 (Add)                    (None, 8, 8, 6)      0           batch_normalization_269[0][0]    \n",
            "                                                                 add_75[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_25 (Gl (None, 6)            0           add_76[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_49 (Dense)                (None, 48)           336         global_average_pooling2d_25[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "re_lu_367 (ReLU)                (None, 48)           0           dense_49[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_50 (Dense)                (None, 2)            98          re_lu_367[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,904\n",
            "Trainable params: 2,796\n",
            "Non-trainable params: 108\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b8PE09TtfZqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mobilenet V2 from scratch"
      ],
      "metadata": {
        "id": "kDn6fRqASmYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def conv_block(inputs, filters, kernel_size, strides):\n",
        "    x = tf.keras.layers.Conv2D(filters, kernel_size, strides=strides, padding='same')(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    return x\n",
        "\n",
        "def bottleneck(inputs, filters, kernel_size, t, strides, use_bias=False):\n",
        "    in_channels = inputs.shape[-1]\n",
        "    x = conv_block(inputs, t * in_channels, 1, 1)\n",
        "    x = tf.keras.layers.DepthwiseConv2D(kernel_size, strides=strides, padding='same', use_bias=use_bias)(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    x = tf.keras.layers.Conv2D(filters, 1, strides=1, padding='same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    if strides == 1 and in_channels == filters:\n",
        "        x = tf.keras.layers.Add()([x, inputs])\n",
        "    return x\n",
        "\n",
        "def mobilenetv2(input_shape, num_classes):\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "    x = conv_block(inputs, 32, 3, strides=2)\n",
        "    x = bottleneck(x, 16, 3, t=1, strides=1)\n",
        "    x = bottleneck(x, 24, 3, t=6, strides=2)\n",
        "    x = bottleneck(x, 24, 3, t=6, strides=1)\n",
        "    x = bottleneck(x, 32, 3, t=6, strides=2)\n",
        "    x = bottleneck(x, 32, 3, t=6, strides=1)\n",
        "    x = bottleneck(x, 64, 3, t=6, strides=2)\n",
        "    x = bottleneck(x, 64, 3, t=6, strides=1)\n",
        "    x = bottleneck(x, 96, 3, t=6, strides=1)\n",
        "    x = bottleneck(x, 96, 3, t=6, strides=1)\n",
        "    x = bottleneck(x, 160, 3, t=6, strides=2)\n",
        "    x = bottleneck(x, 160, 3, t=6, strides=1)\n",
        "    x = bottleneck(x, 320, 3, t=6, strides=1)\n",
        "    x = conv_block(x, 1280, 1, strides=1)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "    return tf.keras.Model(inputs, x)\n",
        "\n",
        "# example usage\n",
        "model = mobilenetv2(input_shape=(224, 224, 3), num_classes=10)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "pWJ5vXIxSuT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n-unizCWTh9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-56JCIhBTh_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.mobilenet import MobileNet\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.applications import MobileNetV3Small\n",
        "from tensorflow.keras.applications import MobileNetV3Large\n",
        "#tf.keras.applications.MobileNetV3Small\n",
        "\n",
        "base_model = MobileNetV3Large(\n",
        "    input_shape=MODEL_IMAGE_SHAPE,\n",
        "    alpha=0.4,\n",
        "    include_top=False,\n",
        "    weights=None, #  'imagenet'\n",
        "    #input_tensor=None,\n",
        "    #pooling=None,\n",
        "    #classes=1000,\n",
        "    #classifier_activation='softmax',\n",
        "    #**kwargs\n",
        ")\n",
        "\n",
        "for layer in base_model.layers: #base_model.layers[:-6] means that consider layer only till 6th last layer from layer 1\n",
        "    layer.trainable = True  \n",
        "\n",
        "\n",
        "\n",
        "# penultimate_layer = model.layers[-2]\n",
        "# new_top_layer = tf.keras.layers.Dense(1)(penultimate_layer.output)  # create new FC layer and connect it to the rest of the model\n",
        "# new_model = tf.keras.models.Model(model.input, new_top_layer)\n",
        "\n",
        "\n",
        "\n",
        "# Use a Sequential model to add a trainable classifier on top\n",
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\"),\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Y6FsGLvTMbA",
        "outputId": "cdeef9eb-7de9-4f48-f03c-2f09a6c10cee"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "MobilenetV3large (Functional (None, 3, 3, 1280)        1031008   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_17  (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 64)                81984     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 1,113,122\n",
            "Trainable params: 1,102,962\n",
            "Non-trainable params: 10,160\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### MobileNetV2"
      ],
      "metadata": {
        "id": "qomxkZHNIlYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/Haikoitoh/paper-implementation/blob/main/MobileNetV2.ipynb\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, DepthwiseConv2D, ReLU, BatchNormalization, add,Softmax, AveragePooling2D, Dense, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def expansion_block(x,t,filters,block_id):\n",
        "    prefix = 'block_{}_'.format(block_id)\n",
        "    total_filters = t*filters\n",
        "    x = Conv2D(total_filters,1,padding='same',use_bias=False, name = prefix +'expand')(x)\n",
        "    x = BatchNormalization(name=prefix +'expand_bn')(x)\n",
        "    x = ReLU(6,name = prefix +'expand_relu')(x)\n",
        "    return x\n",
        "\n",
        "def depthwise_block(x,stride,block_id):\n",
        "    prefix = 'block_{}_'.format(block_id)\n",
        "    x = DepthwiseConv2D(3,strides=(stride,stride),padding ='same', use_bias = False, name = prefix + 'depthwise_conv')(x)\n",
        "    x = BatchNormalization(name=prefix +'dw_bn')(x)\n",
        "    x = ReLU(6,name=prefix +'dw_relu')(x)\n",
        "    return x\n",
        "\n",
        "def projection_block(x,out_channels,block_id):\n",
        "    prefix = 'block_{}_'.format(block_id)\n",
        "    x = Conv2D(filters = out_channels,kernel_size = 1,padding='same',use_bias=False,name= prefix + 'compress')(x)\n",
        "    x = BatchNormalization(name=prefix +'compress_bn')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def Bottleneck(x,t,filters, out_channels,stride,block_id):\n",
        "    y = expansion_block(x,t,filters,block_id)\n",
        "    y = depthwise_block(y,stride,block_id)\n",
        "    y = projection_block(y, out_channels,block_id)\n",
        "    if y.shape[-1]==x.shape[-1]:\n",
        "        y = add([x,y])\n",
        "    return y\n",
        "\n",
        "\n",
        "def MobileNetV2(input_image = (224,224,3), n_classes=1000):\n",
        "    input = Input(input_image)\n",
        "\n",
        "    x1 = tf.keras.layers.AveragePooling2D(pool_size=(5, 5), strides=3)(input)\n",
        "    x2 = tf.keras.layers.MaxPooling2D(pool_size=(5, 5), strides=3)(input)\n",
        "    x = tf.keras.layers.Concatenate()([x1, x2])    \n",
        "\n",
        "    x = Conv2D(1,kernel_size=3,strides=(2,2),padding = 'same', use_bias=False)(x)\n",
        "    x = BatchNormalization(name='conv1_bn')(x)\n",
        "    x = ReLU(6, name = 'conv1_relu')(x)\n",
        "\n",
        "    # 17 Bottlenecks\n",
        "\n",
        "    x = depthwise_block(x,stride=1,block_id=1)\n",
        "    x = projection_block(x, out_channels=4,block_id=1)\n",
        "\n",
        "    x = Bottleneck(x, t = 1, filters = x.shape[-1], out_channels = 6, stride = 2,block_id = 2)\n",
        "    x = Bottleneck(x, t = 1, filters = x.shape[-1], out_channels = 6, stride = 1,block_id = 3)\n",
        "\n",
        "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 32, stride = 2,block_id = 4)\n",
        "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 32, stride = 1,block_id = 5)\n",
        "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 32, stride = 1,block_id = 6)\n",
        "\n",
        "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 64, stride = 2,block_id = 7)\n",
        "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 64, stride = 1,block_id = 8)\n",
        "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 64, stride = 1,block_id = 9)\n",
        "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 64, stride = 1,block_id = 10)\n",
        "\n",
        "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 96, stride = 1,block_id = 11)\n",
        "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 96, stride = 1,block_id = 12)\n",
        "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 96, stride = 1,block_id = 13)\n",
        "\n",
        "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 160, stride = 2,block_id = 14)\n",
        "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 160, stride = 1,block_id = 15)\n",
        "    # x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 160, stride = 1,block_id = 16)\n",
        "\n",
        "    # x = Bottleneck(x, t = 2, filters = x.shape[-1], out_channels = 8, stride = 1,block_id = 17)\n",
        "\n",
        "\n",
        "    #1*1 conv\n",
        "    x = Conv2D(filters = 6,kernel_size = 1,padding='same',use_bias=False, name = 'last_conv')(x)\n",
        "    x = BatchNormalization(name='last_bn')(x)\n",
        "    x = ReLU(6,name='last_relu')(x)\n",
        "\n",
        "    #AvgPool 7*7\n",
        "    x = GlobalAveragePooling2D(name='global_average_pool')(x)\n",
        "    x = tf.keras.layers.Dense(32, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "    output = Dense(n_classes,activation='softmax')(x)\n",
        "\n",
        "    model = Model(input, output)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# n_classes = 1000\n",
        "# input_shape = (224,224,3)\n",
        "\n",
        "# model = MobileNetV2(input_shape,n_classes)\n",
        "# model.summary()   \n",
        "\n",
        "model = MobileNetV2(MODEL_IMAGE_SHAPE, NUM_CLASSES)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYtHrRENIRuh",
        "outputId": "fa8897ef-a1a0-44fb-cb51-d93cb31fd9b6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, 96, 96, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 31, 31, 1)    0           input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 31, 31, 1)    0           input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 31, 31, 2)    0           average_pooling2d[0][0]          \n",
            "                                                                 max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 1)    18          concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 16, 16, 1)    4           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (ReLU)               (None, 16, 16, 1)    0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "block_1_depthwise_conv (Depthwi (None, 16, 16, 1)    9           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block_1_dw_bn (BatchNormalizati (None, 16, 16, 1)    4           block_1_depthwise_conv[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_1_dw_relu (ReLU)          (None, 16, 16, 1)    0           block_1_dw_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block_1_compress (Conv2D)       (None, 16, 16, 4)    4           block_1_dw_relu[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_1_compress_bn (BatchNorma (None, 16, 16, 4)    16          block_1_compress[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_2_expand (Conv2D)         (None, 16, 16, 4)    16          block_1_compress_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_2_expand_bn (BatchNormali (None, 16, 16, 4)    16          block_2_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_2_expand_relu (ReLU)      (None, 16, 16, 4)    0           block_2_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_2_depthwise_conv (Depthwi (None, 8, 8, 4)      36          block_2_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_2_dw_bn (BatchNormalizati (None, 8, 8, 4)      16          block_2_depthwise_conv[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_2_dw_relu (ReLU)          (None, 8, 8, 4)      0           block_2_dw_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block_2_compress (Conv2D)       (None, 8, 8, 6)      24          block_2_dw_relu[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_2_compress_bn (BatchNorma (None, 8, 8, 6)      24          block_2_compress[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_3_expand (Conv2D)         (None, 8, 8, 6)      36          block_2_compress_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_3_expand_bn (BatchNormali (None, 8, 8, 6)      24          block_3_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_3_expand_relu (ReLU)      (None, 8, 8, 6)      0           block_3_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_3_depthwise_conv (Depthwi (None, 8, 8, 6)      54          block_3_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_3_dw_bn (BatchNormalizati (None, 8, 8, 6)      24          block_3_depthwise_conv[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_3_dw_relu (ReLU)          (None, 8, 8, 6)      0           block_3_dw_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block_3_compress (Conv2D)       (None, 8, 8, 6)      36          block_3_dw_relu[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_3_compress_bn (BatchNorma (None, 8, 8, 6)      24          block_3_compress[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 8, 8, 6)      0           block_2_compress_bn[0][0]        \n",
            "                                                                 block_3_compress_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "last_conv (Conv2D)              (None, 8, 8, 6)      36          add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "last_bn (BatchNormalization)    (None, 8, 8, 6)      24          last_conv[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "last_relu (ReLU)                (None, 8, 8, 6)      0           last_bn[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pool (GlobalAver (None, 6)            0           last_relu[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 32)           224         global_average_pool[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 32)           0           dense_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 2)            66          dropout_5[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 735\n",
            "Trainable params: 647\n",
            "Non-trainable params: 88\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ir7cYR41Qqtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5rEhalrFQqzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VWLnw7k10FCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QKUvSSdATMgQ"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3A8Mw3LXPlAN"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ],
      "metadata": {
        "id": "FN6vf2wB3juX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"image_classification_checkpoint.h5\",\n",
        "                             monitor='val_loss',\n",
        "                             mode='min',\n",
        "                             save_best_only=True,verbose=1)\n",
        "\n",
        "earlystop = EarlyStopping(monitor='val_loss',\n",
        "                          min_delta=0,\n",
        "                          patience=2,\n",
        "                          verbose=1,\n",
        "                          restore_best_weights=True)\n",
        "\n",
        "callbacks=[checkpoint,earlystop]\n",
        "\n",
        "model.compile(loss='SparseCategoricalCrossentropy',\n",
        "                   optimizer=Adam(learning_rate=0.0015),\n",
        "                   metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "epochs=200\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                        #  steps_per_epoch=num_train_samples//batch_size,\n",
        "                         epochs=epochs,\n",
        "                        #  callbacks=callbacks,\n",
        "                         validation_data=val_generator,\n",
        "                        #  validation_steps=num_val_samples//batch_size\n",
        "                         )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZywXeOe_SQnj",
        "outputId": "59c96436-16f4-47af-df68-74d40389222c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "75/75 [==============================] - 17s 194ms/step - loss: 0.6100 - sparse_categorical_accuracy: 0.6728 - val_loss: 0.5774 - val_sparse_categorical_accuracy: 0.7200\n",
            "Epoch 2/200\n",
            "75/75 [==============================] - 13s 169ms/step - loss: 0.5992 - sparse_categorical_accuracy: 0.6952 - val_loss: 0.6846 - val_sparse_categorical_accuracy: 0.6300\n",
            "Epoch 3/200\n",
            "75/75 [==============================] - 11s 140ms/step - loss: 0.5957 - sparse_categorical_accuracy: 0.6826 - val_loss: 0.5928 - val_sparse_categorical_accuracy: 0.7050\n",
            "Epoch 4/200\n",
            "75/75 [==============================] - 13s 175ms/step - loss: 0.5705 - sparse_categorical_accuracy: 0.7134 - val_loss: 0.5707 - val_sparse_categorical_accuracy: 0.7150\n",
            "Epoch 5/200\n",
            "75/75 [==============================] - 13s 174ms/step - loss: 0.5975 - sparse_categorical_accuracy: 0.6851 - val_loss: 0.5442 - val_sparse_categorical_accuracy: 0.7250\n",
            "Epoch 6/200\n",
            "75/75 [==============================] - 11s 141ms/step - loss: 0.5894 - sparse_categorical_accuracy: 0.6760 - val_loss: 0.5495 - val_sparse_categorical_accuracy: 0.7150\n",
            "Epoch 7/200\n",
            "75/75 [==============================] - 13s 167ms/step - loss: 0.5873 - sparse_categorical_accuracy: 0.6984 - val_loss: 0.6085 - val_sparse_categorical_accuracy: 0.6250\n",
            "Epoch 8/200\n",
            "75/75 [==============================] - 13s 175ms/step - loss: 0.6034 - sparse_categorical_accuracy: 0.6801 - val_loss: 0.5755 - val_sparse_categorical_accuracy: 0.7250\n",
            "Epoch 9/200\n",
            "75/75 [==============================] - 12s 156ms/step - loss: 0.5860 - sparse_categorical_accuracy: 0.6894 - val_loss: 0.5799 - val_sparse_categorical_accuracy: 0.7250\n",
            "Epoch 10/200\n",
            "75/75 [==============================] - 12s 151ms/step - loss: 0.5803 - sparse_categorical_accuracy: 0.6923 - val_loss: 0.5554 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 11/200\n",
            "75/75 [==============================] - 13s 174ms/step - loss: 0.5813 - sparse_categorical_accuracy: 0.6953 - val_loss: 0.6883 - val_sparse_categorical_accuracy: 0.6250\n",
            "Epoch 12/200\n",
            "75/75 [==============================] - 12s 167ms/step - loss: 0.5839 - sparse_categorical_accuracy: 0.6861 - val_loss: 0.6150 - val_sparse_categorical_accuracy: 0.6650\n",
            "Epoch 13/200\n",
            "75/75 [==============================] - 11s 142ms/step - loss: 0.5721 - sparse_categorical_accuracy: 0.7103 - val_loss: 0.5879 - val_sparse_categorical_accuracy: 0.6850\n",
            "Epoch 14/200\n",
            "75/75 [==============================] - 14s 184ms/step - loss: 0.5627 - sparse_categorical_accuracy: 0.7134 - val_loss: 0.5462 - val_sparse_categorical_accuracy: 0.7200\n",
            "Epoch 15/200\n",
            "75/75 [==============================] - 13s 175ms/step - loss: 0.5844 - sparse_categorical_accuracy: 0.6835 - val_loss: 0.5419 - val_sparse_categorical_accuracy: 0.7150\n",
            "Epoch 16/200\n",
            "75/75 [==============================] - 11s 141ms/step - loss: 0.5734 - sparse_categorical_accuracy: 0.6989 - val_loss: 0.5563 - val_sparse_categorical_accuracy: 0.7200\n",
            "Epoch 17/200\n",
            "75/75 [==============================] - 13s 167ms/step - loss: 0.5852 - sparse_categorical_accuracy: 0.6944 - val_loss: 0.6020 - val_sparse_categorical_accuracy: 0.6950\n",
            "Epoch 18/200\n",
            "75/75 [==============================] - 13s 176ms/step - loss: 0.5797 - sparse_categorical_accuracy: 0.7023 - val_loss: 0.6527 - val_sparse_categorical_accuracy: 0.6600\n",
            "Epoch 19/200\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.5747 - sparse_categorical_accuracy: 0.7103 - val_loss: 0.5941 - val_sparse_categorical_accuracy: 0.6650\n",
            "Epoch 20/200\n",
            "75/75 [==============================] - 12s 156ms/step - loss: 0.5860 - sparse_categorical_accuracy: 0.7000 - val_loss: 0.5821 - val_sparse_categorical_accuracy: 0.6950\n",
            "Epoch 21/200\n",
            "75/75 [==============================] - 13s 177ms/step - loss: 0.5864 - sparse_categorical_accuracy: 0.6974 - val_loss: 0.6101 - val_sparse_categorical_accuracy: 0.6650\n",
            "Epoch 22/200\n",
            "75/75 [==============================] - 13s 168ms/step - loss: 0.5787 - sparse_categorical_accuracy: 0.6972 - val_loss: 0.5751 - val_sparse_categorical_accuracy: 0.7300\n",
            "Epoch 23/200\n",
            "75/75 [==============================] - 11s 143ms/step - loss: 0.5856 - sparse_categorical_accuracy: 0.7018 - val_loss: 0.5729 - val_sparse_categorical_accuracy: 0.6950\n",
            "Epoch 24/200\n",
            "75/75 [==============================] - 13s 174ms/step - loss: 0.5734 - sparse_categorical_accuracy: 0.7108 - val_loss: 0.5681 - val_sparse_categorical_accuracy: 0.7300\n",
            "Epoch 25/200\n",
            "75/75 [==============================] - 13s 175ms/step - loss: 0.5822 - sparse_categorical_accuracy: 0.6975 - val_loss: 0.6048 - val_sparse_categorical_accuracy: 0.6850\n",
            "Epoch 26/200\n",
            "75/75 [==============================] - 11s 141ms/step - loss: 0.5581 - sparse_categorical_accuracy: 0.7170 - val_loss: 0.5532 - val_sparse_categorical_accuracy: 0.7100\n",
            "Epoch 27/200\n",
            "75/75 [==============================] - 13s 169ms/step - loss: 0.5651 - sparse_categorical_accuracy: 0.7063 - val_loss: 0.5526 - val_sparse_categorical_accuracy: 0.7100\n",
            "Epoch 28/200\n",
            "75/75 [==============================] - 13s 175ms/step - loss: 0.5685 - sparse_categorical_accuracy: 0.7062 - val_loss: 0.5734 - val_sparse_categorical_accuracy: 0.7100\n",
            "Epoch 29/200\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.5828 - sparse_categorical_accuracy: 0.7057 - val_loss: 0.5649 - val_sparse_categorical_accuracy: 0.7100\n",
            "Epoch 30/200\n",
            "75/75 [==============================] - 12s 155ms/step - loss: 0.5758 - sparse_categorical_accuracy: 0.6959 - val_loss: 0.5804 - val_sparse_categorical_accuracy: 0.7150\n",
            "Epoch 31/200\n",
            "75/75 [==============================] - 13s 175ms/step - loss: 0.5544 - sparse_categorical_accuracy: 0.7260 - val_loss: 0.6043 - val_sparse_categorical_accuracy: 0.6850\n",
            "Epoch 32/200\n",
            "75/75 [==============================] - 13s 169ms/step - loss: 0.5649 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.5703 - val_sparse_categorical_accuracy: 0.7100\n",
            "Epoch 33/200\n",
            "75/75 [==============================] - 11s 140ms/step - loss: 0.5597 - sparse_categorical_accuracy: 0.7209 - val_loss: 0.5670 - val_sparse_categorical_accuracy: 0.6900\n",
            "Epoch 34/200\n",
            "75/75 [==============================] - 16s 216ms/step - loss: 0.5632 - sparse_categorical_accuracy: 0.7068 - val_loss: 0.5553 - val_sparse_categorical_accuracy: 0.7200\n",
            "Epoch 35/200\n",
            "75/75 [==============================] - 16s 212ms/step - loss: 0.5554 - sparse_categorical_accuracy: 0.7338 - val_loss: 0.5428 - val_sparse_categorical_accuracy: 0.7200\n",
            "Epoch 36/200\n",
            "75/75 [==============================] - 13s 176ms/step - loss: 0.5609 - sparse_categorical_accuracy: 0.7181 - val_loss: 0.5668 - val_sparse_categorical_accuracy: 0.6950\n",
            "Epoch 37/200\n",
            "75/75 [==============================] - 11s 149ms/step - loss: 0.5652 - sparse_categorical_accuracy: 0.7157 - val_loss: 0.5499 - val_sparse_categorical_accuracy: 0.7100\n",
            "Epoch 38/200\n",
            "75/75 [==============================] - 12s 161ms/step - loss: 0.5678 - sparse_categorical_accuracy: 0.7118 - val_loss: 0.5685 - val_sparse_categorical_accuracy: 0.7050\n",
            "Epoch 39/200\n",
            "75/75 [==============================] - 13s 175ms/step - loss: 0.5582 - sparse_categorical_accuracy: 0.7217 - val_loss: 0.6020 - val_sparse_categorical_accuracy: 0.6650\n",
            "Epoch 40/200\n",
            "75/75 [==============================] - 12s 161ms/step - loss: 0.5695 - sparse_categorical_accuracy: 0.7029 - val_loss: 0.5687 - val_sparse_categorical_accuracy: 0.6900\n",
            "Epoch 41/200\n",
            "75/75 [==============================] - 11s 148ms/step - loss: 0.5590 - sparse_categorical_accuracy: 0.7147 - val_loss: 0.5868 - val_sparse_categorical_accuracy: 0.6800\n",
            "Epoch 42/200\n",
            "75/75 [==============================] - 13s 175ms/step - loss: 0.5636 - sparse_categorical_accuracy: 0.7234 - val_loss: 0.5641 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 43/200\n",
            "75/75 [==============================] - 13s 172ms/step - loss: 0.5758 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.6029 - val_sparse_categorical_accuracy: 0.6800\n",
            "Epoch 44/200\n",
            "75/75 [==============================] - 10s 136ms/step - loss: 0.5532 - sparse_categorical_accuracy: 0.7238 - val_loss: 0.5869 - val_sparse_categorical_accuracy: 0.6950\n",
            "Epoch 45/200\n",
            "75/75 [==============================] - 13s 175ms/step - loss: 0.5618 - sparse_categorical_accuracy: 0.7151 - val_loss: 0.5991 - val_sparse_categorical_accuracy: 0.6850\n",
            "Epoch 46/200\n",
            "75/75 [==============================] - 13s 175ms/step - loss: 0.5628 - sparse_categorical_accuracy: 0.7109 - val_loss: 0.5767 - val_sparse_categorical_accuracy: 0.7150\n",
            "Epoch 47/200\n",
            "75/75 [==============================] - 11s 147ms/step - loss: 0.5557 - sparse_categorical_accuracy: 0.7255 - val_loss: 0.5649 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 48/200\n",
            "75/75 [==============================] - 12s 163ms/step - loss: 0.5846 - sparse_categorical_accuracy: 0.6948 - val_loss: 0.6095 - val_sparse_categorical_accuracy: 0.6850\n",
            "Epoch 49/200\n",
            "75/75 [==============================] - 13s 175ms/step - loss: 0.5662 - sparse_categorical_accuracy: 0.7074 - val_loss: 0.6762 - val_sparse_categorical_accuracy: 0.6750\n",
            "Epoch 50/200\n",
            "75/75 [==============================] - 12s 158ms/step - loss: 0.5630 - sparse_categorical_accuracy: 0.7135 - val_loss: 0.5823 - val_sparse_categorical_accuracy: 0.7000\n",
            "Epoch 51/200\n",
            "75/75 [==============================] - 11s 150ms/step - loss: 0.5420 - sparse_categorical_accuracy: 0.7276 - val_loss: 0.5979 - val_sparse_categorical_accuracy: 0.7050\n",
            "Epoch 52/200\n",
            "75/75 [==============================] - 13s 176ms/step - loss: 0.5482 - sparse_categorical_accuracy: 0.7257 - val_loss: 0.5793 - val_sparse_categorical_accuracy: 0.7150\n",
            "Epoch 53/200\n",
            "75/75 [==============================] - 13s 175ms/step - loss: 0.5463 - sparse_categorical_accuracy: 0.7265 - val_loss: 0.5669 - val_sparse_categorical_accuracy: 0.7050\n",
            "Epoch 54/200\n",
            "75/75 [==============================] - 10s 136ms/step - loss: 0.5470 - sparse_categorical_accuracy: 0.7323 - val_loss: 0.5788 - val_sparse_categorical_accuracy: 0.7100\n",
            "Epoch 55/200\n",
            " 1/75 [..............................] - ETA: 19s - loss: 0.5746 - sparse_categorical_accuracy: 0.7500"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-da3a16e69e6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m history = model.fit(train_generator,\n\u001b[0m\u001b[1;32m     26\u001b[0m                         \u001b[0;31m#  steps_per_epoch=num_train_samples//batch_size,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                          \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4f2YbVV3SQp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EAp0Bvviz1t2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OCrwLmP5z1wT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert from tensorflow to tensorflow lite"
      ],
      "metadata": {
        "id": "oCwvSMSSl3D-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H0yrGx2TniiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen=ImageDataGenerator(rescale=1./255,\n",
        "                                 rotation_range=10,\n",
        "                                 width_shift_range=0.1,\n",
        "                                 height_shift_range=0.1,\n",
        "                                 horizontal_flip=True,\n",
        "                                 fill_mode='nearest')\n",
        "generator=datagen.flow_from_directory(val_data_dir,\n",
        "                                      target_size=IMAGE_SHAPE,\n",
        "                                      batch_size=BATCH_SIZE,\n",
        "                                      color_mode=\"grayscale\",\n",
        "                                      class_mode='sparse')\n",
        "def representative_data_gen():\n",
        "  i = 0\n",
        "  for image_batch, labels_batch in generator:\n",
        "    i = i+1\n",
        "    if i > 20:\n",
        "      break;\n",
        "    yield [image_batch]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WZbO7ZJnIG4",
        "outputId": "2887044d-aa94-4646-b919-d2b1a75ee25c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 200 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "print('\\nSetting the optimization flags..')\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_data_gen\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "\n",
        "print('\\nConverting..')\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "open(\"person_detect_model_data.tflite\", \"wb\").write(tflite_model)\n",
        "\n",
        "print(\"Done Conversion\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4mbUSpQfiz5",
        "outputId": "10e423c7-3794-455e-b47c-e092041fe1f4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Setting the optimization flags..\n",
            "\n",
            "Converting..\n",
            "Done Conversion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert from tensorflow to c array"
      ],
      "metadata": {
        "id": "LsNCFAg-l789"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!xxd -i ./person_detect_model_data.tflite > person_detect_model_data.cpp"
      ],
      "metadata": {
        "id": "3lz68gN6rR9o"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!cp /content/person_detect_model_data.cpp /content/person_detect_model_data_copy.cpp"
      ],
      "metadata": {
        "id": "R3DWOMYT0Ymj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "search_text1 = \"unsigned char __person_detect_model_data_tflite[]\"\n",
        "\n",
        "\n",
        "replace_text1 = str('#include \"person_detect_model_data.h\" \\n\\\n",
        "#ifdef __has_attribute \\n\\\n",
        "#define HAVE_ATTRIBUTE(x) __has_attribute(x) \\n\\\n",
        "#else \\n\\\n",
        "#define HAVE_ATTRIBUTE(x) 0 \\n\\\n",
        "#endif \\n\\\n",
        "#if HAVE_ATTRIBUTE(aligned) || (defined(__GNUC__) && !defined(__clang__)) \\n\\\n",
        "#define DATA_ALIGN_ATTRIBUTE __attribute__((aligned(4))) \\n\\\n",
        "#else \\n\\\n",
        "#define DATA_ALIGN_ATTRIBUTE \\n\\\n",
        "#endif \\n\\\n",
        "const unsigned char g_person_detect_model_data[] DATA_ALIGN_ATTRIBUTE')\n",
        "\n",
        "\n",
        "search_text2 = \"unsigned int __person_detect_model_data_tflite_len\"\n",
        "\n",
        "replace_text2 = \"const int g_person_detect_model_data_len\"\n",
        "\n",
        "with open(r'/content/person_detect_model_data.cpp', 'r') as file:\n",
        "\n",
        "    data = file.read()\n",
        "\n",
        "    data = data.replace(search_text1, replace_text1)\n",
        "    data = data.replace(search_text2, replace_text2)\n",
        "  # data = data.replace(search_text2, replace_text2)\n",
        "\n",
        "with open(r'/content/person_detect_model_data.cpp', 'w') as file:\n",
        "    file.write(data)\n",
        "    file.close()\n",
        "\n",
        "\n",
        "\n",
        "print(\"Text replaced\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDErADgkrnec",
        "outputId": "71ecc98a-3d9a-49dc-f016-e6121275d38f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text replaced\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e6jBeDVz8tLF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}