{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPiRtQ6pfmH9t4uHeuk+Tr2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amanglarus/image_classification_using-tensorflow/blob/main/classification_using_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlyECQNKPppm",
        "outputId": "31352172-aa5f-4e2d-df85-037f4178a578"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/tshirt_laptop_data.zip /content/"
      ],
      "metadata": {
        "id": "8TqXEThNQCtk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip tshirt_laptop_data.zip"
      ],
      "metadata": {
        "id": "FOfkvKKKQCwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install specific tensorflow version "
      ],
      "metadata": {
        "id": "xPAXleRl6CPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gpu==2.4.0"
      ],
      "metadata": {
        "id": "VCOBlSpL6Bvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5_FjV1k5_wg",
        "outputId": "1afb27de-780b-4d37-d13f-9aee53e3c53a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q3r7VVtk6AQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oBxCFEGCis-M"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data in pipe line to tarin the model"
      ],
      "metadata": {
        "id": "JmT3vZhI31fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D,Dense,Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, ZeroPadding2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.models import Model, Sequential"
      ],
      "metadata": {
        "id": "7jes4eSpQC1S"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zOkBf541aeQm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 2\n",
        "BATCH_SIZE=32\n",
        "IMAGE_SIZE = 48\n",
        "NUM_CHANNEL = 3\n",
        "\n",
        "IMAGE_SHAPE = (IMAGE_SIZE, IMAGE_SIZE)\n",
        "MODEL_IMAGE_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNEL)"
      ],
      "metadata": {
        "id": "TfsrnPgMaeS1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_data_dir='/content/tshirt_laptop_data/train'\n",
        "val_data_dir='/content/tshirt_laptop_data/test'\n",
        "\n",
        "# from tensorflow.keras.layers.preprocessing.image_preprocessing import HORIZONTAL\n",
        "\n",
        "train_datagen=ImageDataGenerator(rescale=1./255,\n",
        "                                 rotation_range=10,\n",
        "                                 width_shift_range=0.1,\n",
        "                                 height_shift_range=0.1,\n",
        "                                 horizontal_flip=True,\n",
        "                                 fill_mode='nearest')\n",
        "\n",
        "val_datagen=ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_generator=train_datagen.flow_from_directory(train_data_dir,\n",
        "                                                  target_size=IMAGE_SHAPE,\n",
        "                                                  batch_size=BATCH_SIZE,\n",
        "                                                  class_mode='sparse')\n",
        "\n",
        "val_generator=val_datagen.flow_from_directory(val_data_dir,\n",
        "                                              target_size=IMAGE_SHAPE,\n",
        "                                              batch_size=BATCH_SIZE,\n",
        "                                              class_mode='sparse')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCRDX1OyPk91",
        "outputId": "434cdefc-3f51-48ed-f616-b375e9cc97a5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2385 images belonging to 2 classes.\n",
            "Found 200 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Model"
      ],
      "metadata": {
        "id": "zL479Jog3oP_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zcwmu73TQjmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_toJDoxJSrVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mobilenet V3 from scratch\n"
      ],
      "metadata": {
        "id": "AcZN5i1uQjtn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def conv_block(inputs, filters, kernel_size, strides, use_bias=True):\n",
        "    x = tf.keras.layers.Conv2D(filters, kernel_size, strides=strides, padding='same', use_bias=use_bias)(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    return x\n",
        "\n",
        "def bottleneck(inputs, filters, kernel_size, expansion_factor, strides, use_bias=True):\n",
        "    in_channels = inputs.shape[-1]\n",
        "    x = conv_block(inputs, expansion_factor * in_channels, 1, 1, use_bias)\n",
        "    x = conv_block(x, expansion_factor * in_channels, kernel_size, strides, use_bias)\n",
        "    x = tf.keras.layers.Conv2D(filters, 1, strides=1, padding='same', use_bias=use_bias)(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    if strides == 1 and in_channels == filters:\n",
        "        x = tf.keras.layers.Add()([x, inputs])\n",
        "    return x\n",
        "\n",
        "def mobilenetv3_small(input_shape, num_classes):\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "    x = conv_block(inputs, 8, 3, strides=2)\n",
        "    x = bottleneck(x, 8, 3, expansion_factor=1, strides=2)\n",
        "    x = bottleneck(x, 8, 3, expansion_factor=1, strides=1)\n",
        "    x = bottleneck(x, 8, 3, expansion_factor=1, strides=1)\n",
        "    # x = bottleneck(x, 16, 5, expansion_factor=3, strides=2)\n",
        "    # x = bottleneck(x, 16, 5, expansion_factor=3, strides=1)\n",
        "    # x = bottleneck(x, 16, 5, expansion_factor=3, strides=1)\n",
        "    x = conv_block(x, 8, 1, strides=1)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = tf.keras.layers.Dense(48)(x)\n",
        "    x = tf.keras.layers.ReLU(6.)(x)\n",
        "    x = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "    return tf.keras.Model(inputs, x)\n",
        "\n",
        "# example usage\n",
        "model = mobilenetv3_small(input_shape=MODEL_IMAGE_SHAPE, num_classes=NUM_CLASSES)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmgpFEkKTMYF",
        "outputId": "89c2b70a-df35-4747-8305-a548514e6f08"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_16 (InputLayer)           [(None, 48, 48, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 24, 24, 8)    224         input_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 24, 24, 8)    32          conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_72 (ReLU)                 (None, 24, 24, 8)    0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 24, 24, 8)    72          re_lu_72[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 24, 24, 8)    32          conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_73 (ReLU)                 (None, 24, 24, 8)    0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 12, 12, 8)    584         re_lu_73[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 12, 12, 8)    32          conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_74 (ReLU)                 (None, 12, 12, 8)    0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 12, 12, 8)    72          re_lu_74[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 12, 12, 8)    32          conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 12, 12, 8)    72          batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 12, 12, 8)    32          conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_75 (ReLU)                 (None, 12, 12, 8)    0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 12, 12, 8)    584         re_lu_75[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 12, 12, 8)    32          conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_76 (ReLU)                 (None, 12, 12, 8)    0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 12, 12, 8)    72          re_lu_76[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 12, 12, 8)    32          conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 12, 12, 8)    0           batch_normalization_101[0][0]    \n",
            "                                                                 batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 12, 12, 8)    72          add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 12, 12, 8)    32          conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_77 (ReLU)                 (None, 12, 12, 8)    0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 12, 12, 8)    584         re_lu_77[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 12, 12, 8)    32          conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_78 (ReLU)                 (None, 12, 12, 8)    0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 12, 12, 8)    72          re_lu_78[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 12, 12, 8)    32          conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 12, 12, 8)    0           batch_normalization_104[0][0]    \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 12, 12, 8)    72          add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 12, 12, 8)    32          conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_79 (ReLU)                 (None, 12, 12, 8)    0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_8 (Glo (None, 8)            0           re_lu_79[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 48)           432         global_average_pooling2d_8[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_80 (ReLU)                 (None, 48)           0           dense_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 2)            98          re_lu_80[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 3,362\n",
            "Trainable params: 3,186\n",
            "Non-trainable params: 176\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b8PE09TtfZqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mobilenet V2 from scratch"
      ],
      "metadata": {
        "id": "kDn6fRqASmYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def conv_block(inputs, filters, kernel_size, strides):\n",
        "    x = tf.keras.layers.Conv2D(filters, kernel_size, strides=strides, padding='same')(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    return x\n",
        "\n",
        "def bottleneck(inputs, filters, kernel_size, t, strides, use_bias=False):\n",
        "    in_channels = inputs.shape[-1]\n",
        "    x = conv_block(inputs, t * in_channels, 1, 1)\n",
        "    x = tf.keras.layers.DepthwiseConv2D(kernel_size, strides=strides, padding='same', use_bias=use_bias)(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    x = tf.keras.layers.Conv2D(filters, 1, strides=1, padding='same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    if strides == 1 and in_channels == filters:\n",
        "        x = tf.keras.layers.Add()([x, inputs])\n",
        "    return x\n",
        "\n",
        "def mobilenetv2(input_shape, num_classes):\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "    x = conv_block(inputs, 32, 3, strides=2)\n",
        "    x = bottleneck(x, 16, 3, t=1, strides=1)\n",
        "    x = bottleneck(x, 24, 3, t=6, strides=2)\n",
        "    x = bottleneck(x, 24, 3, t=6, strides=1)\n",
        "    x = bottleneck(x, 32, 3, t=6, strides=2)\n",
        "    x = bottleneck(x, 32, 3, t=6, strides=1)\n",
        "    x = bottleneck(x, 64, 3, t=6, strides=2)\n",
        "    x = bottleneck(x, 64, 3, t=6, strides=1)\n",
        "    x = bottleneck(x, 96, 3, t=6, strides=1)\n",
        "    x = bottleneck(x, 96, 3, t=6, strides=1)\n",
        "    x = bottleneck(x, 160, 3, t=6, strides=2)\n",
        "    x = bottleneck(x, 160, 3, t=6, strides=1)\n",
        "    x = bottleneck(x, 320, 3, t=6, strides=1)\n",
        "    x = conv_block(x, 1280, 1, strides=1)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "    return tf.keras.Model(inputs, x)\n",
        "\n",
        "# example usage\n",
        "model = mobilenetv2(input_shape=(224, 224, 3), num_classes=10)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "pWJ5vXIxSuT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ir7cYR41Qqtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5rEhalrFQqzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.mobilenet import MobileNet\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.applications import MobileNetV3Small\n",
        "from tensorflow.keras.applications import MobileNetV3Large\n",
        "#tf.keras.applications.MobileNetV3Small\n",
        "\n",
        "base_model = MobileNetV3Small(\n",
        "    input_shape=MODEL_IMAGE_SHAPE,\n",
        "    alpha=0.2,\n",
        "    include_top=False,\n",
        "    weights=None, #  'imagenet'\n",
        "    #input_tensor=None,\n",
        "    #pooling=None,\n",
        "    #classes=1000,\n",
        "    #classifier_activation='softmax',\n",
        "    #**kwargs\n",
        ")\n",
        "\n",
        "for layer in base_model.layers: #base_model.layers[:-6] means that consider layer only till 6th last layer from layer 1\n",
        "    layer.trainable = True  \n",
        "\n",
        "\n",
        "\n",
        "# penultimate_layer = model.layers[-2]\n",
        "# new_top_layer = tf.keras.layers.Dense(1)(penultimate_layer.output)  # create new FC layer and connect it to the rest of the model\n",
        "# new_model = tf.keras.models.Model(model.input, new_top_layer)\n",
        "\n",
        "\n",
        "\n",
        "# Use a Sequential model to add a trainable classifier on top\n",
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\"),\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Y6FsGLvTMbA",
        "outputId": "98132115-8276-43a6-8dee-97e5f585cf24"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "MobilenetV3small (Functional (None, 2, 2, 1024)        231608    \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                65600     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 297,338\n",
            "Trainable params: 294,058\n",
            "Non-trainable params: 3,280\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0sY4QfRETMd0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QKUvSSdATMgQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3A8Mw3LXPlAN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ],
      "metadata": {
        "id": "FN6vf2wB3juX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"image_classification_checkpoint.h5\",\n",
        "                             monitor='val_loss',\n",
        "                             mode='min',\n",
        "                             save_best_only=True,verbose=1)\n",
        "\n",
        "earlystop = EarlyStopping(monitor='val_loss',\n",
        "                          min_delta=0,\n",
        "                          patience=2,\n",
        "                          verbose=1,\n",
        "                          restore_best_weights=True)\n",
        "\n",
        "callbacks=[checkpoint,earlystop]\n",
        "\n",
        "model.compile(loss='SparseCategoricalCrossentropy',\n",
        "                   optimizer=Adam(learning_rate=0.0015),\n",
        "                   metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "epochs=2\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                        #  steps_per_epoch=num_train_samples//batch_size,\n",
        "                         epochs=epochs,\n",
        "                        #  callbacks=callbacks,\n",
        "                         validation_data=val_generator,\n",
        "                        #  validation_steps=num_val_samples//batch_size\n",
        "                         )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZywXeOe_SQnj",
        "outputId": "072404bd-a9bd-40a4-d737-ab3cfeb467e6"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "75/75 [==============================] - 20s 248ms/step - loss: 0.6665 - sparse_categorical_accuracy: 0.6071 - val_loss: 0.7084 - val_sparse_categorical_accuracy: 0.5150\n",
            "Epoch 2/2\n",
            "75/75 [==============================] - 18s 242ms/step - loss: 0.5991 - sparse_categorical_accuracy: 0.6756 - val_loss: 0.8340 - val_sparse_categorical_accuracy: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4f2YbVV3SQp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert from tensorflow to tensorflow lite"
      ],
      "metadata": {
        "id": "oCwvSMSSl3D-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H0yrGx2TniiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen=ImageDataGenerator(rescale=1./255,\n",
        "                                 rotation_range=10,\n",
        "                                 width_shift_range=0.1,\n",
        "                                 height_shift_range=0.1,\n",
        "                                 horizontal_flip=True,\n",
        "                                 fill_mode='nearest')\n",
        "generator=datagen.flow_from_directory(val_data_dir,\n",
        "                                      target_size=IMAGE_SHAPE,\n",
        "                                      batch_size=BATCH_SIZE,\n",
        "                                      class_mode='sparse')\n",
        "def representative_data_gen():\n",
        "  i = 0\n",
        "  for image_batch, labels_batch in generator:\n",
        "    i = i+1\n",
        "    if i > 20:\n",
        "      break;\n",
        "    yield [image_batch]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WZbO7ZJnIG4",
        "outputId": "020f0e08-cd67-4943-8ac3-96c435659cee"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 200 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "print('\\nSetting the optimization flags..')\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_data_gen\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "\n",
        "print('\\nConverting..')\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "open(\"person_detect_model_data.tflite\", \"wb\").write(tflite_model)\n",
        "\n",
        "print(\"Done Conversion\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4mbUSpQfiz5",
        "outputId": "269c3fb7-58ea-49c3-c16b-06cd354ec3b1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Setting the optimization flags..\n",
            "\n",
            "Converting..\n",
            "Done Conversion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert from tensorflow to c array"
      ],
      "metadata": {
        "id": "LsNCFAg-l789"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!xxd -i ./person_detect_model_data.tflite > person_detect_model_data.cpp"
      ],
      "metadata": {
        "id": "3lz68gN6rR9o"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!cp /content/person_detect_model_data.cpp /content/person_detect_model_data_copy.cpp"
      ],
      "metadata": {
        "id": "R3DWOMYT0Ymj"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "search_text1 = \"unsigned char __person_detect_model_data_tflite[]\"\n",
        "\n",
        "\n",
        "replace_text1 = str('#include \"person_detect_model_data.h\" \\n\\\n",
        "#ifdef __has_attribute \\n\\\n",
        "#define HAVE_ATTRIBUTE(x) __has_attribute(x) \\n\\\n",
        "#else \\n\\\n",
        "#define HAVE_ATTRIBUTE(x) 0 \\n\\\n",
        "#endif \\n\\\n",
        "#if HAVE_ATTRIBUTE(aligned) || (defined(__GNUC__) && !defined(__clang__)) \\n\\\n",
        "#define DATA_ALIGN_ATTRIBUTE __attribute__((aligned(4))) \\n\\\n",
        "#else \\n\\\n",
        "#define DATA_ALIGN_ATTRIBUTE \\n\\\n",
        "#endif \\n\\\n",
        "const unsigned char g_person_detect_model_data[] DATA_ALIGN_ATTRIBUTE')\n",
        "\n",
        "\n",
        "search_text2 = \"unsigned int __person_detect_model_data_tflite_len\"\n",
        "\n",
        "replace_text2 = \"const int g_person_detect_model_data_len\"\n",
        "\n",
        "with open(r'/content/person_detect_model_data.cpp', 'r') as file:\n",
        "\n",
        "    data = file.read()\n",
        "\n",
        "    data = data.replace(search_text1, replace_text1)\n",
        "    data = data.replace(search_text2, replace_text2)\n",
        "  # data = data.replace(search_text2, replace_text2)\n",
        "\n",
        "with open(r'/content/person_detect_model_data.cpp', 'w') as file:\n",
        "    file.write(data)\n",
        "    file.close()\n",
        "\n",
        "\n",
        "\n",
        "print(\"Text replaced\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDErADgkrnec",
        "outputId": "f210de39-c92e-4e42-9e33-b6b1cddb4221"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text replaced\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e6jBeDVz8tLF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}